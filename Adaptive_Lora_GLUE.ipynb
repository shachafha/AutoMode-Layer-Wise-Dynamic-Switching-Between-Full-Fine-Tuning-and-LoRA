{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Adaptive LoRA for GLUE Benchmark\n",
        "This notebook implements an Adaptive LoRA (Low-Rank Adaptation) strategy for fine-tuning transformers on the GLUE benchmark. The approach dynamically adjusts the active LoRA adapters during training based on entropy and gradient signals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation\n",
        "Installing the necessary libraries: `transformers`, `datasets`, `evaluate`, `peft`, `accelerate`, and `tqdm`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9cyoGUjo3cpl1EZGBe92Zj3h",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cyoGUjo3cpl1EZGBe92Zj3h",
        "outputId": "9362feeb-e644-4204-fa87-a07d1112ced8",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Install complete.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade \"transformers>=4.36.0\" \"datasets\" \"evaluate\" \"peft>=0.6.0\" \"accelerate\" \"tqdm\"\n",
        "print(\"Install complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Setup\n",
        "Importing standard libraries and Deep Learning frameworks (PyTorch, Hugging Face Transformers). We also define the computation device (CUDA/CPU) and a seeding function for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "yfCJ5Cvwv-eZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfCJ5Cvwv-eZ",
        "outputId": "127e12a1-a7d3-4eb7-a6d8-9a84b15ab249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os, math, time, random, json\n",
        "from collections import defaultdict, OrderedDict, deque\n",
        "from typing import Dict, Any, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    get_scheduler\n",
        ")\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "import evaluate\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "    print(\"Seed set to\", seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading and Tokenization\n",
        "We use the Hugging Face `datasets` library to load GLUE tasks.\n",
        "\n",
        "The function `load_and_tokenize_glue` handles:\n",
        "1.  Loading the raw dataset.\n",
        "2.  Initializing the tokenizer.\n",
        "3.  Tokenizing the input text fields appropriate for the specific GLUE task (e.g., single sentence vs. sentence pairs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "75krAYcXwDPr",
      "metadata": {
        "id": "75krAYcXwDPr"
      },
      "outputs": [],
      "source": [
        "TASK_TO_KEYS = {\n",
        "    'rte': ('sentence1', 'sentence2'),\n",
        "    'sst2': ('sentence', None),\n",
        "    'qnli': ('question', 'sentence'),\n",
        "    'mrpc': ('sentence1', 'sentence2'),\n",
        "    'mnli': ('premise', 'hypothesis'),\n",
        "    'stsb': ('sentence1', 'sentence2'),\n",
        "}\n",
        "\n",
        "def get_num_labels_from_raw(raw_dataset):\n",
        "    \"\"\"Extract the number of labels from a raw GLUE dataset.\"\"\"\n",
        "    try:\n",
        "        feat = raw_dataset['train'].features['label']\n",
        "        if hasattr(feat, \"num_classes\"):\n",
        "            return int(feat.num_classes)\n",
        "    except Exception:\n",
        "        pass\n",
        "    labels = raw_dataset['train']['label']\n",
        "    return int(max(labels)) + 1\n",
        "\n",
        "def load_and_tokenize_glue(task_name: str, model_checkpoint: str, max_length: int = 128):\n",
        "    print(f\"Loading GLUE task '{task_name}' and tokenizer '{model_checkpoint}'\")\n",
        "    raw = load_dataset(\"glue\", task_name)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
        "    key1, key2 = TASK_TO_KEYS[task_name]\n",
        "\n",
        "    def tokenize_batch(examples):\n",
        "        if key2 is None:\n",
        "            enc = tokenizer(examples[key1], truncation=True, padding=\"max_length\", max_length=max_length)\n",
        "        else:\n",
        "            enc = tokenizer(examples[key1], examples[key2], truncation=True, padding=\"max_length\", max_length=max_length)\n",
        "        enc[\"labels\"] = examples[\"label\"]  # ensure labels column exists\n",
        "        return enc\n",
        "\n",
        "    remove_cols = raw[\"train\"].column_names\n",
        "    tokenized = raw.map(tokenize_batch, batched=True, remove_columns=remove_cols)\n",
        "    cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "    if \"token_type_ids\" in tokenized[\"train\"].column_names:\n",
        "        cols.insert(1, \"token_type_ids\")\n",
        "    tokenized.set_format(type=\"torch\", columns=cols)\n",
        "    num_labels = get_num_labels_from_raw(raw)\n",
        "    print(f\"Tokenized. Train size: {len(tokenized['train'])} Val size: {len(tokenized['validation'])} num_labels: {num_labels}\")\n",
        "    return raw, tokenized, tokenizer, num_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Construction\n",
        "Helper functions to load a pre-trained sequence classification model and apply LoRA (Low-Rank Adaptation) configuration using `peft`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "zsCIobArwKw7",
      "metadata": {
        "id": "zsCIobArwKw7"
      },
      "outputs": [],
      "source": [
        "def get_target_modules_for_model(model_name: str) -> List[str]:\n",
        "    # broad matching list for common transformer attention/proj components\n",
        "    return [\"q_lin\", \"k_lin\", \"v_lin\", \"out_lin\", \"query\", \"key\", \"value\", \"proj\", \"dense\", \"linear\"]\n",
        "\n",
        "def build_model_with_lora(model_checkpoint: str, num_labels: int, lora_cfg: Dict[str, Any]):\n",
        "    print(f\"Loading base model {model_checkpoint} and applying LoRA\")\n",
        "    base = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
        "    peft_cfg = LoraConfig(\n",
        "        r=lora_cfg.get(\"r\", 16),\n",
        "        lora_alpha=lora_cfg.get(\"lora_alpha\", 32),\n",
        "        lora_dropout=lora_cfg.get(\"lora_dropout\", 0.1),\n",
        "        bias=\"none\",\n",
        "        task_type=\"SEQ_CLS\",\n",
        "        target_modules=get_target_modules_for_model(model_checkpoint)\n",
        "    )\n",
        "    model = get_peft_model(base, peft_cfg)\n",
        "    model.to(DEVICE)\n",
        "    try:\n",
        "        model.print_trainable_parameters()\n",
        "    except Exception:\n",
        "        pass\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adapter Importance Metrics\n",
        "Functions to estimate the \"importance\" of LoRA adapters.\n",
        "\n",
        "- `compute_adapter_importance_safe`: Calculates the norm of LoRA weights (A or B matrices).\n",
        "- `entropy_of_distribution`: Calculates the Shannon entropy of a normalized distribution of importance scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ekOO8Q9AwSXS",
      "metadata": {
        "id": "ekOO8Q9AwSXS"
      },
      "outputs": [],
      "source": [
        "def iter_named_lora_modules(model):\n",
        "    \"\"\"Yield (name, module) for modules that contain LoRA params (heuristic).\"\"\"\n",
        "    for name, module in model.named_modules():\n",
        "        # presence of lora_A or lora_B attributes is typical\n",
        "        if hasattr(module, \"lora_A\") or hasattr(module, \"lora_B\"):\n",
        "            yield name, module\n",
        "\n",
        "def compute_adapter_importance_safe(name: str, module) -> float:\n",
        "    \"\"\"Proxy importance: use norm of lora_B or lora_A where present.\"\"\"\n",
        "    try:\n",
        "        if hasattr(module, \"lora_B\"):\n",
        "            lb = getattr(module, \"lora_B\")\n",
        "            if isinstance(lb, torch.Tensor):\n",
        "                return float(torch.norm(lb).cpu().item())\n",
        "            if hasattr(lb, \"weight\"):\n",
        "                return float(torch.norm(lb.weight).cpu().item())\n",
        "        if hasattr(module, \"lora_A\"):\n",
        "            la = getattr(module, \"lora_A\")\n",
        "            if isinstance(la, torch.Tensor):\n",
        "                return float(torch.norm(la).cpu().item())\n",
        "            if hasattr(la, \"weight\"):\n",
        "                return float(torch.norm(la.weight).cpu().item())\n",
        "    except Exception:\n",
        "        pass\n",
        "    return 0.0\n",
        "\n",
        "def entropy_of_distribution(d: Dict[str, float]) -> float:\n",
        "    \"\"\"Shannon entropy of normalized distribution (in nats).\"\"\"\n",
        "    vals = np.array(list(d.values()), dtype=float)\n",
        "    s = np.sum(vals)\n",
        "    if s == 0:\n",
        "        return 0.0\n",
        "    p = vals / s\n",
        "    # avoid log(0)\n",
        "    p = p[p > 0]\n",
        "    return float(-np.sum(p * np.log(p)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adaptive LoRA Controller\n",
        "The `AdaptiveLoRAControllerV3` class manages the dynamic selection of active LoRA layers during training.\n",
        "\n",
        "**Key Mechanisms:**\n",
        "- **Entropy-based Layer Selection**: Uses the entropy of importance scores to determine how many and which layers to activate.\n",
        "- **Cosine Scheduling**: Smoothly varies hyperparameters (alpha, combine ratio) over epochs.\n",
        "- **Gating**: Optional soft gating or hard freezing of adapters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4yJpir9nwW_B",
      "metadata": {
        "id": "4yJpir9nwW_B"
      },
      "outputs": [],
      "source": [
        "class AdaptiveLoRAControllerV3:\n",
        "    \"\"\"\n",
        "    - Uses entropy-based layer selection\n",
        "    - Uses cosine schedules for alpha (weight vs grad mix) and combine ratio\n",
        "    - adaptations_per_epoch scheduling\n",
        "    - optional gating (soft) or hard freeze\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        train_dataloader: DataLoader,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        adaptations_per_epoch: int = 5,\n",
        "        importance_threshold: float = 0.85,\n",
        "        min_layers: int = 2,\n",
        "        cooldown_steps_between_toggles: int = 2,\n",
        "        smoothing_alpha: float = 0.3,\n",
        "        use_gating: bool = False,\n",
        "        alpha_start: float = 0.5,\n",
        "        alpha_end: float = 0.9,\n",
        "        combine_start: float = 0.5,\n",
        "        combine_end: float = 0.9,\n",
        "        total_epochs: int = 5\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        self.steps_per_epoch = max(1, len(train_dataloader))\n",
        "        self.adaptations_per_epoch = max(1, adaptations_per_epoch)\n",
        "        self.adaptation_interval = max(1, self.steps_per_epoch // self.adaptations_per_epoch)\n",
        "\n",
        "        self.importance_threshold = importance_threshold\n",
        "        self.min_layers = min_layers\n",
        "        self.cooldown = cooldown_steps_between_toggles\n",
        "        self.smoothing_alpha = smoothing_alpha\n",
        "        self.use_gating = use_gating\n",
        "\n",
        "        # schedule params\n",
        "        self.alpha_start = alpha_start\n",
        "        self.alpha_end = alpha_end\n",
        "        self.combine_start = combine_start\n",
        "        self.combine_end = combine_end\n",
        "        self.total_epochs = max(1, total_epochs)\n",
        "\n",
        "        self.step = 0\n",
        "        self.epoch = 0\n",
        "        self.adapter_weight_acc = defaultdict(float)\n",
        "        self.gradient_acc = {}  # param_id -> [sum_sq, cnt]\n",
        "        self.smoothed_scores = {}\n",
        "        self.last_toggled = defaultdict(lambda: -999999)\n",
        "        self.freezing_log = []\n",
        "\n",
        "        # adapters discovery\n",
        "        self.adapters = OrderedDict()\n",
        "        self.param_to_adapter = {}\n",
        "        self._discover_adapters()\n",
        "\n",
        "        if self.use_gating:\n",
        "            self._init_gates()\n",
        "\n",
        "    def _discover_adapters(self):\n",
        "        for name, module in iter_named_lora_modules(self.model):\n",
        "            self.adapters[name] = module\n",
        "            for p in module.parameters():\n",
        "                self.param_to_adapter[id(p)] = name\n",
        "\n",
        "    def _init_gates(self):\n",
        "        self.gates = nn.ParameterDict()\n",
        "        for name in self.adapters:\n",
        "            key = name.replace(\".\", \"_\")\n",
        "            self.gates[key] = nn.Parameter(torch.tensor(1.0, device=next(self.model.parameters()).device))\n",
        "\n",
        "    def compute_initial_importance(self, num_batches: int = 20):\n",
        "        \"\"\"Warm-start: forward a few batches, accumulate adapter norms as proxy.\"\"\"\n",
        "        self.adapter_weight_acc.clear()\n",
        "        device = next(self.model.parameters()).device\n",
        "        it = iter(self.train_dataloader)\n",
        "        for i in range(num_batches):\n",
        "            try:\n",
        "                batch = next(it)\n",
        "            except StopIteration:\n",
        "                break\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            with torch.no_grad():\n",
        "                _ = self.model(**batch)\n",
        "            for name, module in self.adapters.items():\n",
        "                self.adapter_weight_acc[name] += compute_adapter_importance_safe(name, module)\n",
        "        total = sum(self.adapter_weight_acc.values()) + 1e-12\n",
        "        for k, v in self.adapter_weight_acc.items():\n",
        "            self.smoothed_scores[k] = v / total if total > 0 else 0.0\n",
        "\n",
        "    def accumulate_gradients(self):\n",
        "        \"\"\"Call after loss.backward(). Accumulate grad norms per param, mapped to adapters.\"\"\"\n",
        "        for p in self.model.parameters():\n",
        "            if p.grad is None:\n",
        "                continue\n",
        "            pid = id(p)\n",
        "            if pid not in self.param_to_adapter:\n",
        "                continue\n",
        "            gnorm = float(torch.norm(p.grad.detach(), p=2).cpu().item())\n",
        "            if pid not in self.gradient_acc:\n",
        "                self.gradient_acc[pid] = [0.0, 0]\n",
        "            self.gradient_acc[pid][0] += gnorm ** 2\n",
        "            self.gradient_acc[pid][1] += 1\n",
        "\n",
        "    def _cosine_scheduler(self, step_or_epoch: float, total: float, start: float, end: float) -> float:\n",
        "        \"\"\"Cosine schedule from start -> end over total (step_or_epoch in [0,total]).\"\"\"\n",
        "        if total <= 1:\n",
        "            return end\n",
        "        x = min(max(step_or_epoch / total, 0.0), 1.0)\n",
        "        cosv = 0.5 * (1 + math.cos(math.pi * (1 - x)))  # cosine ramp (0->1)\n",
        "        return start * (1 - cosv) + end * cosv\n",
        "\n",
        "    def _compute_combined_scores(self):\n",
        "        \"\"\"Combine weight (smoothed) + grad signals with dynamically scheduled mixing.\"\"\"\n",
        "        # aggregate param grads to adapter-level\n",
        "        adapter_grad_sum = defaultdict(float)\n",
        "        adapter_grad_cnt = defaultdict(int)\n",
        "        for pid, (sum_sq, cnt) in self.gradient_acc.items():\n",
        "            adapter_name = self.param_to_adapter.get(pid)\n",
        "            if adapter_name is None: continue\n",
        "            adapter_grad_sum[adapter_name] += sum_sq\n",
        "            adapter_grad_cnt[adapter_name] += cnt\n",
        "\n",
        "        # compute grad_score per adapter\n",
        "        grad_scores = {}\n",
        "        for name in self.adapters.keys():\n",
        "            if adapter_grad_cnt[name] > 0:\n",
        "                avg_grad = math.sqrt(adapter_grad_sum[name] / (adapter_grad_cnt[name] + 1e-12))\n",
        "                grad_scores[name] = math.log1p(avg_grad)\n",
        "            else:\n",
        "                grad_scores[name] = 0.0\n",
        "\n",
        "        # schedule alpha and combine_ratio using epoch progress\n",
        "        alpha = self._cosine_scheduler(self.epoch, self.total_epochs, self.alpha_start, self.alpha_end)\n",
        "        combine_ratio = self._cosine_scheduler(self.epoch, self.total_epochs, self.combine_start, self.combine_end)\n",
        "        # weight_score = smoothed_scores (structure); grad_score = grad_scores\n",
        "        raw = {}\n",
        "        for name in self.adapters.keys():\n",
        "            weight_score = self.smoothed_scores.get(name, 0.0)\n",
        "            gs = grad_scores.get(name, 0.0)\n",
        "            # first blend weight vs grad with alpha (alpha = weight weight, 1-alpha = grad)\n",
        "            blended = alpha * weight_score + (1 - alpha) * gs\n",
        "            # then apply combine_ratio (another blending stage if desired)\n",
        "            raw[name] = combine_ratio * blended + (1 - combine_ratio) * weight_score\n",
        "\n",
        "        # normalize raw -> probabilities\n",
        "        tot = sum(raw.values()) + 1e-12\n",
        "        normalized = {k: v / tot for k, v in raw.items()}\n",
        "\n",
        "        # smoothing w/ previous smoothed_scores\n",
        "        new_smoothed = {}\n",
        "        for k, v in normalized.items():\n",
        "            prev = self.smoothed_scores.get(k, v)\n",
        "            new_smoothed[k] = self.smoothing_alpha * v + (1 - self.smoothing_alpha) * prev\n",
        "        # final normalization\n",
        "        s_tot = sum(new_smoothed.values()) + 1e-12\n",
        "        return {k: v / s_tot for k, v in new_smoothed.items()}, alpha, combine_ratio\n",
        "\n",
        "    def _select_active_entropy(self, scores: Dict[str, float]):\n",
        "        \"\"\"Entropy-aware selection: when entropy high, allow more active layers.\"\"\"\n",
        "        # sorted descending\n",
        "        items = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        # dynamic multiplier from entropy\n",
        "        H = entropy_of_distribution(scores)\n",
        "        # normalize entropy to [0,1] heuristically by log(K)\n",
        "        K = max(1, len(scores))\n",
        "        max_H = math.log(K + 1e-12)\n",
        "        entropy_factor = H / (max_H + 1e-12)  # 0..1\n",
        "        # base target cumulative threshold can be tightened or loosened by entropy_factor\n",
        "        eff_threshold = self.importance_threshold * (0.5 + 0.5 * entropy_factor)  # if entropy high -> threshold closer to original or larger\n",
        "        active = set()\n",
        "        cum = 0.0\n",
        "        for k, v in items:\n",
        "            active.add(k)\n",
        "            cum += v\n",
        "            if cum >= eff_threshold:\n",
        "                break\n",
        "        # ensure minimum\n",
        "        i = 0\n",
        "        while len(active) < self.min_layers and i < len(items):\n",
        "            active.add(items[i][0]); i += 1\n",
        "        return active, H, eff_threshold\n",
        "\n",
        "    def _refresh_optimizer(self):\n",
        "        \"\"\"Rebuild optimizer to reflect newly trainable params.\"\"\"\n",
        "        try:\n",
        "            params = [p for p in self.model.parameters() if p.requires_grad]\n",
        "            OptimCls = type(self.optimizer)\n",
        "            new_optim = OptimCls(params, **self.optimizer.defaults)\n",
        "            try:\n",
        "                new_optim.load_state_dict(self.optimizer.state_dict())\n",
        "            except Exception:\n",
        "                pass\n",
        "            self.optimizer = new_optim\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    def maybe_adapt(self):\n",
        "        \"\"\"Call each training step; performs adaptation when it's time.\"\"\"\n",
        "        self.step += 1\n",
        "        if (self.step % self.adaptation_interval) != 0:\n",
        "            return False\n",
        "        # compute combined scores using current epoch\n",
        "        combined_scores, alpha, combine_ratio = self._compute_combined_scores()\n",
        "        if not combined_scores:\n",
        "            return False\n",
        "        # select active set using entropy-aware method\n",
        "        active, entropy_val, effective_threshold = self._select_active_entropy(combined_scores)\n",
        "        changed = False\n",
        "        now = self.step\n",
        "        for name, module in self.adapters.items():\n",
        "            if (now - self.last_toggled[name]) < self.cooldown:\n",
        "                continue\n",
        "            should_active = (name in active)\n",
        "            currently_active = any(p.requires_grad for p in module.parameters())\n",
        "            if self.use_gating:\n",
        "                key = name.replace(\".\", \"_\"); gate = self.gates[key]\n",
        "                new_val = 1.0 if should_active else 0.0\n",
        "                if float(gate.data) != new_val:\n",
        "                    gate.data = torch.tensor(new_val, device=gate.device); changed = True\n",
        "            else:\n",
        "                if should_active and not currently_active:\n",
        "                    for p in module.parameters(): p.requires_grad = True\n",
        "                    changed = True; self.last_toggled[name] = now\n",
        "                elif (not should_active) and currently_active:\n",
        "                    for p in module.parameters(): p.requires_grad = False\n",
        "                    changed = True; self.last_toggled[name] = now\n",
        "        if changed and not self.use_gating:\n",
        "            self._refresh_optimizer()\n",
        "        # log\n",
        "        active_norms = [combined_scores[n] for n in active] if active else []\n",
        "        threshold_used = min(active_norms) if active_norms else 0.0\n",
        "        self.freezing_log.append({\n",
        "            \"step\": self.step,\n",
        "            \"epoch\": self.epoch,\n",
        "            \"alpha\": alpha,\n",
        "            \"combine_ratio\": combine_ratio,\n",
        "            \"entropy\": entropy_val,\n",
        "            \"effective_threshold\": effective_threshold,\n",
        "            \"threshold\": threshold_used,\n",
        "            \"active\": list(active),\n",
        "            \"sample_scores\": dict(list(combined_scores.items())[:20]),\n",
        "            \"trainable_params\": sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "        })\n",
        "        # reset gradient accumulator\n",
        "        self.gradient_acc.clear()\n",
        "        # update smoothed scores\n",
        "        self.smoothed_scores.update(combined_scores)\n",
        "        return changed\n",
        "\n",
        "    def set_epoch(self, epoch_idx: int):\n",
        "        self.epoch = epoch_idx\n",
        "        # optionally decay smoothing or other hyperparams per epoch here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Evaluation Loop\n",
        "Functions to execute the training process using the Adaptive Controller.\n",
        "- `evaluate_model`: Runs the model on the validation set.\n",
        "- `train_adaptive_v3`: Sets up the optimizer, scheduler, and controller, then runs the training loop, periodically calling `controller.maybe_adapt()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "r2ZDEJNAwg-l",
      "metadata": {
        "id": "r2ZDEJNAwg-l"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    preds, refs = [], []\n",
        "    for batch in dataloader:\n",
        "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            out = model(**batch)\n",
        "        logits = out.logits\n",
        "        p = torch.argmax(logits, dim=-1).cpu().tolist()\n",
        "        r = batch[\"labels\"].cpu().tolist()\n",
        "        preds.extend(p); refs.extend(r)\n",
        "    return evaluate.load(\"accuracy\").compute(predictions=preds, references=refs)\n",
        "\n",
        "def train_adaptive_v3(cfg, tokenized, tokenizer):\n",
        "    # dataloaders\n",
        "    train_loader = DataLoader(tokenized[\"train\"], batch_size=cfg[\"batch_size\"], shuffle=True,\n",
        "                              collate_fn=DataCollatorWithPadding(tokenizer))\n",
        "    val_loader = DataLoader(tokenized[\"validation\"], batch_size=cfg[\"batch_size\"], shuffle=False,\n",
        "                            collate_fn=DataCollatorWithPadding(tokenizer))\n",
        "\n",
        "    # model + LoRA\n",
        "    model = build_model_with_lora(cfg[\"model\"], cfg[\"num_labels\"], cfg[\"lora_config\"])\n",
        "    optimizer = torch.optim.AdamW([p for p in model.parameters() if p.requires_grad], lr=cfg[\"lr\"])\n",
        "\n",
        "    # controller\n",
        "    controller = AdaptiveLoRAControllerV3(\n",
        "        model=model,\n",
        "        train_dataloader=train_loader,\n",
        "        optimizer=optimizer,\n",
        "        adaptations_per_epoch=cfg.get(\"adaptations_per_epoch\", 5),\n",
        "        importance_threshold=cfg.get(\"importance_threshold\", 0.85),\n",
        "        min_layers=cfg.get(\"min_layers\", 2),\n",
        "        cooldown_steps_between_toggles=cfg.get(\"cooldown\", 2),\n",
        "        smoothing_alpha=cfg.get(\"smoothing_alpha\", 0.3),\n",
        "        use_gating=cfg.get(\"use_gating\", False),\n",
        "        alpha_start=cfg.get(\"alpha_start\", 0.5),\n",
        "        alpha_end=cfg.get(\"alpha_end\", 0.9),\n",
        "        combine_start=cfg.get(\"combine_start\", 0.5),\n",
        "        combine_end=cfg.get(\"combine_end\", 0.9),\n",
        "        total_epochs=cfg[\"epochs\"]\n",
        "    )\n",
        "\n",
        "    if cfg.get(\"compute_initial_importance\", True):\n",
        "        controller.compute_initial_importance(num_batches=min(10, len(train_loader)))\n",
        "\n",
        "    total_steps = cfg[\"epochs\"] * len(train_loader)\n",
        "    scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "    results = []\n",
        "    freezing_log = []\n",
        "\n",
        "    for epoch in range(cfg[\"epochs\"]):\n",
        "        set_seed(cfg.get(\"seed\", 42))\n",
        "        controller.set_epoch(epoch)\n",
        "        model.train()\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{cfg['epochs']}\")\n",
        "        for step, batch in enumerate(pbar):\n",
        "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "            out = model(**batch)\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "            controller.accumulate_gradients()\n",
        "            changed = controller.maybe_adapt()\n",
        "            if changed:\n",
        "                freezing_log.extend(controller.freezing_log[-1:])\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            pbar.set_postfix(loss=loss.item())\n",
        "        # eval\n",
        "        acc = evaluate_model(model, val_loader)\n",
        "        print(f\"Epoch {epoch+1} accuracy:\", acc)\n",
        "        results.append({\"epoch\": epoch+1, \"metrics\": acc, \"trainable_params\": sum(p.numel() for p in model.parameters() if p.requires_grad)})\n",
        "    return results, freezing_log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment Configuration\n",
        "Defining the grid of hyperparameters and settings for experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "T43Xwl5uwnuq",
      "metadata": {
        "id": "T43Xwl5uwnuq"
      },
      "outputs": [],
      "source": [
        "def build_experiment_grid(models=None, tasks=None):\n",
        "    if models is None:\n",
        "        models = [\"distilbert-base-uncased\"]\n",
        "    if tasks is None:\n",
        "        tasks = [\"sst2\"]  # quick test: choose 1-2 tasks\n",
        "    LRS = [2e-5]\n",
        "    LORA_CFGS = [{\"r\": 16, \"lora_alpha\": 32, \"lora_dropout\": 0.1}]\n",
        "    ADAPT_CFGS = [{\n",
        "        \"adaptations_per_epoch\": 8,\n",
        "        \"importance_threshold\": 0.85,\n",
        "        \"min_layers\": 2,\n",
        "        \"compute_initial_importance\": True\n",
        "    }]\n",
        "    exps = []\n",
        "    eid = 0\n",
        "    for m in models:\n",
        "        for t in tasks:\n",
        "            for strategy in [\"adaptive_v3\"]:\n",
        "                for lr in LRS:\n",
        "                    for lcfg in LORA_CFGS:\n",
        "                        cfg = {\n",
        "                            \"exp_id\": f\"grid_{eid:03d}\",\n",
        "                            \"model\": m,\n",
        "                            \"task\": t,\n",
        "                            \"strategy\": strategy,\n",
        "                            \"lr\": lr,\n",
        "                            \"batch_size\": 32,\n",
        "                            \"epochs\": 2,\n",
        "                            \"seed\": 42,\n",
        "                            \"lora_config\": lcfg\n",
        "                        }\n",
        "                        cfg.update(ADAPT_CFGS[0])\n",
        "                        exps.append(cfg)\n",
        "                        eid += 1\n",
        "    print(\"Total experiments:\", len(exps))\n",
        "    return exps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment Execution\n",
        "Running the defined grid of experiments, saving results to CSV and JSON logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "vyUQM9akwyad",
      "metadata": {
        "id": "vyUQM9akwyad"
      },
      "outputs": [],
      "source": [
        "def run_grid(experiments, save_dir=\"./results_v3\"):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    master = []\n",
        "    for cfg in experiments:\n",
        "        print(\"\\n=== Running\", cfg[\"exp_id\"], cfg[\"strategy\"], cfg[\"model\"], \"===\")\n",
        "        set_seed(cfg[\"seed\"])\n",
        "        try:\n",
        "            raw, tokenized, tokenizer, num_labels = load_and_tokenize_glue(cfg[\"task\"], cfg[\"model\"], max_length=128)\n",
        "            cfg[\"num_labels\"] = num_labels\n",
        "            res, log = train_adaptive_v3(cfg, tokenized, tokenizer)\n",
        "            master.extend([dict(cfg, **r) for r in res])\n",
        "            pd.json_normalize(res).to_csv(os.path.join(save_dir, f\"{cfg['exp_id']}_results.csv\"), index=False)\n",
        "            with open(os.path.join(save_dir, f\"{cfg['exp_id']}_freezing.json\"), \"w\") as f:\n",
        "                json.dump(log, f, indent=2)\n",
        "            print(\"Saved results for\", cfg[\"exp_id\"])\n",
        "        except Exception as e:\n",
        "            print(\"\u26a0\ufe0f Experiment failed:\", e)\n",
        "    if master:\n",
        "        pd.json_normalize(master).to_csv(os.path.join(save_dir, \"master_results.csv\"), index=False)\n",
        "    return master"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Sanity Check\n",
        "Running a small-scale experiment (1 task, 1 model) to verify that the pipeline works correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "NJqPNaRFw16u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437,
          "referenced_widgets": [
            "307bb92119c04001ae30afd7c6df3870",
            "882778cae9ce41eb9cc82ca54b66607a",
            "d4e33882b2534f6eb5a085747eec85e5",
            "392826e7116546938bd3f58eea83402b",
            "3c70ed8aac3247ae9dd92cfc239f19d9",
            "6429b317636b4cf29f3ef680ef86eee6",
            "066cc695918e4f1a87bc0dee56aee11f",
            "84c46e1a6ead4d82888743236070a7df",
            "0e8da9eeb0d64aa8a3633b03f72a3693",
            "970b66c58c63418cb35ca574047da079",
            "26627e8f18ad40a6983b54e251517cba",
            "6c918753383543ceac5f91c99e500e1f",
            "f9c6bf88f3dc4ca2b3bbc59e6d194c4b",
            "b081e6adbdeb466d8d985a994313e7a3",
            "126402d1f24d45c7b0da6d97a6f30042",
            "62e8d86f173f4e88a7275943dc139a6a",
            "c6d5cd2a9949413eb4c88bbecb9db566",
            "ce96ac8ebc1645c9b87bca565997bf3d",
            "c684b9cb4b8e4e2095719e1a09610b2d",
            "fe4e8d19379f4a08b237c939afc124ba",
            "783db270150a4a78891a62003514a9c1",
            "ef608fb1b7b04465b26cc9f14cf300d0",
            "fed041307c1d4b27a84d8c31ad3d922d",
            "8d26983b04194a92993425dfbb767bd2",
            "b5097a0013d94ecdae8155ce2dda266a",
            "5a4bcf2f67ba4626906543e5d6c9b170",
            "0864fa90b05a4f6da9c90234cdf846b7",
            "c5ea8d3159304372a3e9d9fe51291b1d",
            "163d204bd6584cc3bd59e79b339c429b",
            "44df93af1d774adebd39466e71824e5e",
            "7f5b29dc3ee24bcda8d0d710f97f8b45",
            "a77b0653b7974a3ea92f32df2fb3a700",
            "6cdb885f49c54ef79365984983d426d1"
          ]
        },
        "id": "NJqPNaRFw16u",
        "outputId": "26187786-1246-49c0-e36e-cce38d26ad6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total experiments: 1\n",
            "Grid: [{'exp_id': 'grid_000', 'model': 'distilbert-base-uncased', 'task': 'sst2', 'strategy': 'adaptive_v3', 'lr': 2e-05, 'batch_size': 32, 'epochs': 2, 'seed': 42, 'lora_config': {'r': 16, 'lora_alpha': 32, 'lora_dropout': 0.1}, 'adaptations_per_epoch': 8, 'importance_threshold': 0.85, 'min_layers': 2, 'compute_initial_importance': True}]\n",
            "\n",
            "=== Running grid_000 adaptive_v3 distilbert-base-uncased ===\n",
            "Seed set to 42\n",
            "Loading GLUE task 'sst2' and tokenizer 'distilbert-base-uncased'\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "307bb92119c04001ae30afd7c6df3870",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized. Train size: 67349 Val size: 872 num_labels: 2\n",
            "Loading base model distilbert-base-uncased and applying LoRA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,181,954 || all params: 68,136,964 || trainable%: 1.7347\n",
            "Seed set to 42\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c918753383543ceac5f91c99e500e1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1/2:   0%|          | 0/2105 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 accuracy: {'accuracy': 0.841743119266055}\n",
            "Seed set to 42\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fed041307c1d4b27a84d8c31ad3d922d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 2/2:   0%|          | 0/2105 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 accuracy: {'accuracy': 0.8520642201834863}\n",
            "Saved results for grid_000\n",
            "Done. experiments: 2\n"
          ]
        }
      ],
      "source": [
        "grid = build_experiment_grid(models=[\"distilbert-base-uncased\"], tasks=[\"sst2\"])\n",
        "print(\"Grid:\", grid)\n",
        "master_results = run_grid(grid, save_dir=\"./results_v3\")\n",
        "print(\"Done. experiments:\", len(master_results))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization\n",
        "Plotting the number of trainable parameters over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "vJLKBRnTw5XX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "vJLKBRnTw5XX",
        "outputId": "d0c65540-9848-4763-a80a-546afb8ef495"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_trainable_params_from_log(logfile):\n",
        "    with open(logfile, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    steps = [e['step'] for e in data]\n",
        "    tp = [e['trainable_params'] for e in data]\n",
        "    plt.plot(steps, tp, marker='o')\n",
        "    plt.xlabel(\"Step\"); plt.ylabel(\"Trainable params\"); plt.grid(True)\n",
        "\n",
        "# Example usage:\n",
        "plot_trainable_params_from_log(\"./results_v3/grid_000_freezing.json\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "name": "av3334 (Nov 18, 2025, 10:27:53\u202fPM)",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}